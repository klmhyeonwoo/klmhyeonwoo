import feedparser
import datetime
import os
import json

feed_list = ["https://klmhyeonwooo.tistory.com?í”„ë¡ íŠ¸ì—”ë“œ ê¹€í˜„ìš°", 
             "https://youngkdevlog.tistory.com/?iOS ì†¡ì˜ê·œ", 
             "https://apape1225.tistory.com?ë°±ì—”ë“œ ì„±ì°½ê·œ", 
             "https://starlikedh.tistory.com?ë°±ì—”ë“œ ì •ë‹¤í˜œ", 
             "https://v2.velog.io/rss/handmk?ë°±ì—”ë“œ ì†ë¯¼ê¸°", 
             "https://v2.velog.io/rss/yunh03?ë°±ì—”ë“œ ì „ìœ¤í™˜", 
             "https://ub775.tistory.com?ë°±ì—”ë“œ ê°•ëª…ê· ",
             "https://suho0303.tistory.com?ë°±ì—”ë“œ ì´ìˆ˜í˜¸"]

markdown_text = """
<div align="center">
  
![dino.gif](./dino.gif)

</div>

## klm hyeon woo

<span style="color:#4E5968; font-size:10px;">
ë¸Œëœë”©ì„ ì¢‹ì•„í•˜ëŠ” ê°œë°œìì…ë‹ˆë‹¤ ğŸ¦„

### íšŒê³ ë¡
- [ê°œë°œìëŠ” ë‚´ê°€ ë§Œë“œëŠ” ì œí’ˆì— ëŒ€í•œ ì• ì •ì„ ê°€ì ¸ì•¼í•œë‹¤](https://klmhyeonwooo.tistory.com/122)<br>
- [ê·¸ ë™ì•ˆ ë‚¨ì˜ ì‹œì„ ì—ì„œ ë²—ì–´ë‚˜ì§€ ëª»í–ˆë˜ ê²ƒ ê°™ë‹¤](https://klmhyeonwooo.tistory.com/65)<br>
- [ì •ë“  ë©‹ìŸì´ì‚¬ìì²˜ëŸ¼ì„ ë– ë‚˜ë©°](https://klmhyeonwooo.tistory.com/89)<br>
- [ë¦¬í¬ë£¨íŒ…ì„ ìœ„í•´ ì–´í”Œë¼ì´ ì‚¬ì´íŠ¸ë¥¼ ê°œë°œí–ˆë‹¤](https://klmhyeonwooo.tistory.com/74)<br>

### ìµœê·¼ í¬ìŠ¤íŒ…
"""

lst = []
parsing_data = {}
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
BASE_DIR += "/data"
print(BASE_DIR)
uniqueKey = 0

for BLOG_URL in feed_list:
    if (BLOG_URL.find("velog.io") != -1):
        feed = feedparser.parse(BLOG_URL.split("?")[0])
    else:
        feed = feedparser.parse(BLOG_URL.split("?")[0]+"/rss")
      
    writer = BLOG_URL.split("?")[1]
    for i in feed['entries']:
        # print(i)
        if (BLOG_URL.find("velog.io") != -1):
          parsing_data["feed-" + str(uniqueKey)] = { 
              "title" : i['title'],
              "link" : i['link'],
              "date" : datetime.datetime.strptime(i['published'], '%a, %d %b %Y %H:%M:%S %Z').strftime("%b %d, %Y"),
              "writer" : writer,
          }
        else:
            parsing_data["feed-" + str(uniqueKey)] = { 
              "title" : i['title'],
              "link" : i['link'],
              "date" : datetime.datetime.strptime(i['published'], "%a, %d %b %Y %H:%M:%S %z").strftime("%b %d, %Y"),
              "writer" : writer,
            }
        print("-", i['link'], i['title'])
        uniqueKey += 1

parsing_data = dict(sorted(parsing_data.items(), key=lambda item: datetime.datetime.strptime(item[1]['date'], '%b %d, %Y'), reverse=True))

feed = feedparser.parse(feed_list[0].split("?")[0]+"/rss")
for i in feed['entries']:
    # print(i)
    markdown_text += f"- [{i['title']}]({i['link']})<br>\n"
  
with open(os.path.join(BASE_DIR, 'feed.json'), 'w+',encoding='utf-8') as json_file:
    json.dump(parsing_data, json_file, ensure_ascii = False, indent='\t')

print(parsing_data)
f = open("README.md", mode="w", encoding="utf-8")
f.write(markdown_text)
f.close()
print("ì„±ê³µ")
